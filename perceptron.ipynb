{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sindhutej-6/dl_programs/blob/main/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTZUhixmOM-P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (AND gate)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 0, 0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias\n",
        "weights = np.array([0.0, 0.0])\n",
        "bias = 0"
      ],
      "metadata": {
        "id": "BZdIkFILOX_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One iteration of Perceptron\n",
        "for i in range(len(X)):\n",
        "    x1, x2 = X[i]\n",
        "    target = y[i]\n",
        "\n",
        "    # Compute z = w.x + b\n",
        "    z = weights[0] * x1 + weights[1] * x2 + bias\n",
        "\n",
        "    # Activation function\n",
        "    output = 1 if z >= 0 else 0\n",
        "\n",
        "    # Update rule without learning rate or error term\n",
        "    if output != target:\n",
        "        if target == 1:\n",
        "            # Add input to weights and increment bias\n",
        "            weights[0] += x1\n",
        "            weights[1] += x2\n",
        "            bias += 1\n",
        "        else:\n",
        "            # Subtract input from weights and decrement bias\n",
        "            weights[0] -= x1\n",
        "            weights[1] -= x2\n",
        "            bias -= 1"
      ],
      "metadata": {
        "id": "P6QXrQj3gh6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final result\n",
        "print(\"Weights after one iteration:\", weights)\n",
        "print(\"Bias after one iteration:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H69V_djjhL0L",
        "outputId": "f5af2150-6aef-4e17-95ed-f862dec8684b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after one iteration: [1. 1.]\n",
            "Bias after one iteration: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perceptron Convergence**"
      ],
      "metadata": {
        "id": "kmc84QP_ltk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Input data (AND gate)\n",
        "X = np.array([[0, 0],\n",
        "              [0, 1],\n",
        "              [1, 0],\n",
        "              [1, 1]])\n",
        "\n",
        "# Target output\n",
        "y = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.array([0, 0])\n",
        "bias = 0"
      ],
      "metadata": {
        "id": "GlrfnJ_-mPt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 0\n",
        "\n",
        "while True:\n",
        "    error_count = 0  # Track number of misclassifications in an epoch\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x1, x2 = X[i]\n",
        "        target = y[i]\n",
        "\n",
        "        # Compute net input\n",
        "        z = weights[0] * x1 + weights[1] * x2 + bias\n",
        "\n",
        "        # Activation function (step function)\n",
        "        output = 1 if z >= 0 else 0\n",
        "\n",
        "        # Update rule (only if prediction is wrong)\n",
        "        if output != target:\n",
        "            error_count += 1\n",
        "            if target == 1:\n",
        "                weights[0] += x1\n",
        "                weights[1] += x2\n",
        "                bias += 1\n",
        "            else:\n",
        "                weights[0] -= x1\n",
        "                weights[1] -= x2\n",
        "                bias -= 1\n",
        "\n",
        "    epochs += 1\n",
        "    # Stop if no errors in this epoch\n",
        "    if error_count == 0:\n",
        "        break"
      ],
      "metadata": {
        "id": "W6jRSw5Cmbhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final result\n",
        "print(\"Training complete in\", epochs, \"epochs\")\n",
        "print(\"Final weights:\", weights)\n",
        "print(\"Final bias:\", bias)\n",
        "\n",
        "# Test the trained model\n",
        "print(\"\\nTesting on all inputs:\")\n",
        "for i in range(len(X)):\n",
        "    x1, x2 = X[i]\n",
        "    z = weights[0] * x1 + weights[1] * x2 + bias\n",
        "    output = 1 if z >= 0 else 0\n",
        "    print(f\"Input: {X[i]} → Output: {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByVfkjrhm31R",
        "outputId": "5812a829-aad5-4126-8c79-23ed3c4fecb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 6 epochs\n",
            "Final weights: [2 1]\n",
            "Final bias: -3\n",
            "\n",
            "Testing on all inputs:\n",
            "Input: [0 0] → Output: 0\n",
            "Input: [0 1] → Output: 0\n",
            "Input: [1 0] → Output: 0\n",
            "Input: [1 1] → Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Perceptron Model using Tensorflow**"
      ],
      "metadata": {
        "id": "n0mnD0M-n9sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Input data (AND gate)\n",
        "X = tf.constant([[0, 0],\n",
        "                 [0, 1],\n",
        "                 [1, 0],\n",
        "                 [1, 1]], dtype=tf.float32)\n",
        "\n",
        "# Target output\n",
        "y = tf.constant([0, 0, 0, 1], dtype=tf.float32)"
      ],
      "metadata": {
        "id": "-VfYM-X7oE9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and bias as TensorFlow variables\n",
        "weights = tf.Variable([0.0, 0.0], dtype=tf.float32)\n",
        "bias = tf.Variable(0.0, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "0BGogvHyoPUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define activation function (step function)\n",
        "def activation(z):\n",
        "    return tf.where(z >= 0, 1.0, 0.0)"
      ],
      "metadata": {
        "id": "mZHp_fzToXcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 0\n",
        "while True:\n",
        "    error_count = 0\n",
        "    for i in range(4):\n",
        "        xi = X[i]\n",
        "        target = y[i]\n",
        "\n",
        "        # Compute z = w.x + b\n",
        "        z = tf.reduce_sum(weights * xi) + bias\n",
        "\n",
        "        # Step activation\n",
        "        output = activation(z)\n",
        "\n",
        "        # Check prediction\n",
        "        if output != target:\n",
        "            error_count += 1\n",
        "            # Update weights and bias using perceptron rule\n",
        "            if target == 1.0:\n",
        "                weights.assign_add(xi)\n",
        "                bias.assign_add(1.0)\n",
        "            else:\n",
        "                weights.assign_sub(xi)\n",
        "                bias.assign_sub(1.0)\n",
        "\n",
        "    epochs += 1\n",
        "    if error_count == 0:\n",
        "        break"
      ],
      "metadata": {
        "id": "ZMy0Tn5EodPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final weights and bias\n",
        "print(f\"Training complete in {epochs} epochs\")\n",
        "print(\"Final weights:\", weights.numpy())\n",
        "print(\"Final bias:\", bias.numpy())\n",
        "\n",
        "# Test on all inputs\n",
        "print(\"\\nTesting on all inputs:\")\n",
        "for i in range(4):\n",
        "    xi = X[i]\n",
        "    z = tf.reduce_sum(weights * xi) + bias\n",
        "    output = activation(z)\n",
        "    print(f\"Input: {xi.numpy()} → Output: {int(output.numpy())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAb_KQTuokcc",
        "outputId": "c75f27c6-c544-40e4-aed1-3e43675db611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 6 epochs\n",
            "Final weights: [2. 1.]\n",
            "Final bias: -3.0\n",
            "\n",
            "Testing on all inputs:\n",
            "Input: [0. 0.] → Output: 0\n",
            "Input: [0. 1.] → Output: 0\n",
            "Input: [1. 0.] → Output: 0\n",
            "Input: [1. 1.] → Output: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XOR using MLP**"
      ],
      "metadata": {
        "id": "1g_W2SJFwi8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 1. Define XOR data\n",
        "# Input: [0,0], [0,1], [1,0], [1,1]\n",
        "# Output: 0, 1, 1, 0\n",
        "X = tf.constant([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=tf.float32)\n",
        "y = tf.constant([[0], [1], [1], [0]], dtype=tf.float32)\n",
        "\n",
        "print(\"X (Input):\")\n",
        "print(X)\n",
        "print(\"\\ny (Output):\")\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAQVI8ePFi8h",
        "outputId": "e822eaef-406e-46c0-cb65-78512d1bf0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (Input):\n",
            "tf.Tensor(\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]], shape=(4, 2), dtype=float32)\n",
            "\n",
            "y (Output):\n",
            "tf.Tensor(\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]], shape=(4, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Build the MLP model\n",
        "# A simple MLP for XOR typically needs at least one hidden layer.\n",
        "# We'll use a hidden layer with 2 neurons and a ReLU activation,\n",
        "# and an output layer with 1 neuron and a Sigmoid activation.\n",
        "model = Sequential([\n",
        "    # Hidden layer\n",
        "    Dense(units=2, activation='relu', input_shape=(2,)), # 2 neurons, ReLU activation, input shape is 2 features\n",
        "    # Output layer\n",
        "    Dense(units=1, activation='sigmoid') # 1 neuron for binary output, Sigmoid activation\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDCQQufoHc8G",
        "outputId": "20983d61-cb9a-407c-fb85-8c3ce0f65afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Compile the model\n",
        "# Optimizer: 'adam' is a good general-purpose optimizer.\n",
        "# Loss function: 'binary_crossentropy' is suitable for binary classification.\n",
        "# Metrics: 'accuracy' to monitor performance.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "4fkYDTmrII9-",
        "outputId": "2ce65780-e642-4f68-e12b-c817d1f7443a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the model\n",
        "# We'll train for a sufficient number of epochs to allow the model to learn the XOR pattern.\n",
        "print(\"\\nTraining the model...\")\n",
        "history = model.fit(X, y, epochs=1000, verbose=0) # verbose=0 to suppress epoch-by-epoch output\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"\\nModel Evaluation:\")\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "print(\"\\nPredictions on XOR inputs:\")\n",
        "predictions = model.predict(X)\n",
        "for i in range(len(X)):\n",
        "    print(f\"Input: {X[i]}, Expected Output: {y[i][0]}, Predicted Output: {predictions[i][0]:.4f} (Rounded: {round(predictions[i][0])})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvH0NcayIizu",
        "outputId": "249a1783-f5e0-4712-9911-73edc9bff988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Training finished.\n",
            "\n",
            "Model Evaluation:\n",
            "Loss: 0.5545\n",
            "Accuracy: 0.7500\n",
            "\n",
            "Predictions on XOR inputs:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "Input: [0. 0.], Expected Output: 0.0, Predicted Output: 0.5755 (Rounded: 1)\n",
            "Input: [0. 1.], Expected Output: 1.0, Predicted Output: 0.5754 (Rounded: 1)\n",
            "Input: [1. 0.], Expected Output: 1.0, Predicted Output: 0.5754 (Rounded: 1)\n",
            "Input: [1. 1.], Expected Output: 0.0, Predicted Output: 0.2257 (Rounded: 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Extract optimized weights and biases\n",
        "print(\"\\nOptimized Weights and Biases:\")\n",
        "for i, layer in enumerate(model.layers):\n",
        "    weights, biases = layer.get_weights()\n",
        "    print(f\"\\nLayer {i+1} ({layer.name}):\")\n",
        "    print(f\"  Weights:\\n{weights}\")\n",
        "    print(f\"  Biases:\\n{biases}\")"
      ],
      "metadata": {
        "id": "PKOK_dBFKBo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ab54a2-7f47-4686-d2df-29030da7afe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized Weights and Biases:\n",
            "\n",
            "Layer 1 (dense):\n",
            "  Weights:\n",
            "[[0.5183574  0.65111184]\n",
            " [0.51804125 0.6517276 ]]\n",
            "  Biases:\n",
            "[-0.5181446  -0.65166914]\n",
            "\n",
            "Layer 2 (dense_1):\n",
            "  Weights:\n",
            "[[-1.1466573]\n",
            " [-1.4476727]]\n",
            "  Biases:\n",
            "[0.30414066]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# 1. Define XOR data\n",
        "# Input: [0,0], [0,1], [1,0], [1,1]\n",
        "# Output: 0, 1, 1, 0\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "print(\"X (Input):\")\n",
        "print(X)\n",
        "print(\"\\ny (Output):\")\n",
        "print(y)\n",
        "\n",
        "# 2. Build the MLP model\n",
        "# A simple MLP for XOR typically needs at least one hidden layer.\n",
        "# We'll use a hidden layer with 2 neurons and a ReLU activation,\n",
        "# and an output layer with 1 neuron and a Sigmoid activation.\n",
        "model = keras.Sequential([\n",
        "    # Hidden layer\n",
        "    keras.layers.Dense(units=2, activation='relu', input_shape=(2,)), # 2 neurons, ReLU activation, input shape is 2 features\n",
        "    # Output layer\n",
        "    keras.layers.Dense(units=1, activation='sigmoid') # 1 neuron for binary output, Sigmoid activation\n",
        "])\n",
        "\n",
        "# 3. Compile the model\n",
        "# Optimizer: 'adam' is a good general-purpose optimizer.\n",
        "# Loss function: 'binary_crossentropy' is suitable for binary classification.\n",
        "# Metrics: 'accuracy' to monitor performance.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# 4. Train the model\n",
        "# We'll train for a sufficient number of epochs to allow the model to learn the XOR pattern.\n",
        "print(\"\\nTraining the model...\")\n",
        "history = model.fit(X, y, epochs=1000, verbose=0) # verbose=0 to suppress epoch-by-epoch output\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print(f\"\\nModel Evaluation:\")\n",
        "print(f\"Loss: {loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Make predictions\n",
        "print(\"\\nPredictions on XOR inputs:\")\n",
        "predictions = model.predict(X)\n",
        "for i in range(len(X)):\n",
        "    print(f\"Input: {X[i]}, Expected Output: {y[i][0]}, Predicted Output: {predictions[i][0]:.4f} (Rounded: {round(predictions[i][0])})\")\n",
        "\n",
        "# 5. Extract optimized weights and biases\n",
        "print(\"\\nOptimized Weights and Biases:\")\n",
        "for i, layer in enumerate(model.layers):\n",
        "    weights, biases = layer.get_weights()\n",
        "    print(f\"\\nLayer {i+1} ({layer.name}):\")\n",
        "    print(f\"  Weights:\\n{weights}\")\n",
        "    print(f\"  Biases:\\n{biases}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LLeaRJ3rwpO8",
        "outputId": "2e9a1ec7-3824-45de-a935-a096c54fd0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (Input):\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "\n",
            "y (Output):\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training the model...\n",
            "Training finished.\n",
            "\n",
            "Model Evaluation:\n",
            "Loss: 0.5069\n",
            "Accuracy: 0.7500\n",
            "\n",
            "Predictions on XOR inputs:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Input: [0. 0.], Expected Output: 0.0, Predicted Output: 0.3785 (Rounded: 0)\n",
            "Input: [0. 1.], Expected Output: 1.0, Predicted Output: 0.9008 (Rounded: 1)\n",
            "Input: [1. 0.], Expected Output: 1.0, Predicted Output: 0.3785 (Rounded: 0)\n",
            "Input: [1. 1.], Expected Output: 0.0, Predicted Output: 0.3787 (Rounded: 0)\n",
            "\n",
            "Optimized Weights and Biases:\n",
            "\n",
            "Layer 1 (dense):\n",
            "  Weights:\n",
            "[[-0.07738602 -1.1933011 ]\n",
            " [-0.09386194  1.1939737 ]]\n",
            "  Biases:\n",
            "[ 0.         -0.00037959]\n",
            "\n",
            "Layer 2 (dense_1):\n",
            "  Weights:\n",
            "[[-0.5832497]\n",
            " [ 2.2640784]]\n",
            "  Biases:\n",
            "[-0.49571183]\n"
          ]
        }
      ]
    }
  ]
}